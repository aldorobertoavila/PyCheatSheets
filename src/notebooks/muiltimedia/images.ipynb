{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dotenv\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_path(dimensions, suffix):\n",
    "    return f'{temp_folder}/{dimensions[0]}x{dimensions[1]}-{suffix}.jpg'\n",
    "\n",
    "def resize(img, dimensions):\n",
    "    return cv2.resize(img, dimensions, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "temp_folder = os.getenv('TEMP_FOLDER')\n",
    "# dimensions = (width, height)\n",
    "picsum_dimensions = (1000, 1000)\n",
    "resized_dimensions = (500, 500)\n",
    "cropped_dimensions = (500, 500)\n",
    "\n",
    "# Original\n",
    "picsum_path = make_image_path(picsum_dimensions, 'picsum')\n",
    "\n",
    "# Size Transformation\n",
    "resized_path = make_image_path(resized_dimensions, 'resized')\n",
    "cropped_path = make_image_path(cropped_dimensions, 'cropped')\n",
    "\n",
    "# Color Correction\n",
    "gray_path = make_image_path(picsum_dimensions, 'gray')\n",
    "summer_path = make_image_path(picsum_dimensions, 'summer')\n",
    "winter_path = make_image_path(picsum_dimensions, 'winter')\n",
    "\n",
    "# Edge Detection\n",
    "blur_path = make_image_path(picsum_dimensions, 'blur')\n",
    "canny_path = make_image_path(picsum_dimensions, 'canny')\n",
    "dilated_path = make_image_path(picsum_dimensions, 'dilated')\n",
    "eroded_path = make_image_path(picsum_dimensions, 'eroded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download an Image from a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "res = requests.get(f'https://picsum.photos/{picsum_dimensions[0]}/{picsum_dimensions[1]}', stream=True)\n",
    "\n",
    "if(res.status_code == 200):\n",
    "    with open(picsum_path, 'wb') as img:\n",
    "        for chunk in res.iter_content(1024):\n",
    "            img.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(picsum_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = resize(img, resized_dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img[height, width]\n",
    "cropped = img[250:750, 250:750]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "summer = cv2.cvtColor(img, cv2.COLORMAP_SUMMER)\n",
    "winter = cv2.cvtColor(img, cv2.COLORMAP_WINTER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(img, (7, 7), cv2.BORDER_DEFAULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(blur, 125, 175)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilated = cv2.dilate(canny, (7, 7), iterations=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eroded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = cv2.erode(dilated, (3, 3), iterations=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size Transformation\n",
    "cv2.imwrite(resized_path, resized)\n",
    "cv2.imwrite(cropped_path, cropped)\n",
    "# Color Correction\n",
    "cv2.imwrite(gray_path, gray)\n",
    "cv2.imwrite(summer_path, summer)\n",
    "cv2.imwrite(winter_path, winter)\n",
    "# Edge Detection\n",
    "cv2.imwrite(blur_path, blur)\n",
    "cv2.imwrite(canny_path, canny)\n",
    "cv2.imwrite(dilated_path, dilated)\n",
    "cv2.imwrite(eroded_path, eroded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show\n",
    "Note: Do not press any key, close the windows manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Size Transformation\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Resized', resized)\n",
    "# Color Correction\n",
    "cv2.imshow('Cropped', cropped)\n",
    "cv2.imshow('Gray', gray)\n",
    "cv2.imshow('Summer', summer)\n",
    "cv2.imshow('Winter', winter)\n",
    "# Edge Detection\n",
    "cv2.imshow('Blur', blur)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.imshow('Dilated', dilated)\n",
    "cv2.imshow('Eroded', eroded)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8bfdcd2cc888dbc98ffcff3cf621025027ffe71c6f18c0bca769d24baae26b7f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
